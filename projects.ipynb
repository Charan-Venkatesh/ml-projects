{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74FAxabFl5Iz",
        "outputId": "bb43853a-d404-4897-b5e7-24a03975e830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "iapRMFB2mL7I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "def download_vader_lexicon():\n",
        "    try:\n",
        "        nltk.download('vader_lexicon')\n",
        "    except LookupError:\n",
        "        nltk.download('vader_lexicon')\n",
        "\n",
        "def initialize_sentiment_analyzer():\n",
        "    return SentimentIntensityAnalyzer()\n",
        "\n",
        "def analyze_sentiment(message, sid):\n",
        "    sentiment_scores = sid.polarity_scores(message)\n",
        "    compound_score = sentiment_scores['compound']\n",
        "\n",
        "    if compound_score >= 0.05:\n",
        "        return \"positive\"\n",
        "    elif compound_score <= -0.05:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "def get_sentiment_emoji(sentiment):\n",
        "    emoji_mapping = {\n",
        "        \"positive\": \"😃\",\n",
        "        \"negative\": \"😔\",\n",
        "        \"neutral\": \"😐\"\n",
        "    }\n",
        "    return emoji_mapping.get(sentiment, \"😐\")\n",
        "\n",
        "def chatbot():\n",
        "    download_vader_lexicon()\n",
        "    sid = initialize_sentiment_analyzer()\n",
        "\n",
        "    print(\"Chatbot: Hello! How can I assist you today?\")\n",
        "\n",
        "    conversation_history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Remove the non-printable character from the user input:\n",
        "        user_input = user_input.replace(u'\\u00A0', '')\n",
        "\n",
        "        # Perform NLP-based sentence analysis:\n",
        "        sentiment = analyze_sentiment(user_input, sid)\n",
        "        sentiment_emoji = get_sentiment_emoji(sentiment)\n",
        "\n",
        "        # Extract keywords and named entities:\n",
        "        keywords = nltk.extract_keywords(user_input)\n",
        "        named_entities = nltk.ne_chunk(nltk.pos_tag(user_input.split()))\n",
        "\n",
        "        # Generate a response based on the NLP analysis and conversation history:\n",
        "        response = response_for_sentiment(sentiment, conversation_history, keywords, named_entities)\n",
        "        conversation_history.append((user_input, response))\n",
        "\n",
        "        print(f\"Chatbot {sentiment_emoji}: {response}\")\n",
        "\n",
        "        # Display conversation history:\n",
        "        print(\"\\nConversation History:\")\n",
        "        for i, (input_text, response_text) in enumerate(conversation_history, start=1):\n",
        "            print(f\"{i}. You: {input_text}\")\n",
        "            print(f\"  Chatbot: {response_text}\\n\")\n",
        "\n",
        "def response_for_sentiment(sentiment, conversation_history, keywords, named_entities):\n",
        "    responses = {\n",
        "        \"positive\": [\"That's wonderful!\", \"Great to hear!\", \"Tell me more about it.\"],\n",
        "        \"negative\": [\"I'm sorry to hear that. Can I help in any way?\", \"I'm here to listen. What's bothering you?\", \"Let's talk about it.\"],\n",
        "        \"neutral\": [\"I understand. How can I assist you further?\", \"Is there anything else you'd like to discuss?\", \"Feel free to ask me anything.\"]\n",
        "    }\n",
        "\n",
        "    # Check the last user input to determine the context of the conversation:\n",
        "    if conversation_history:\n",
        "        last_user_input, _ = conversation_history[-1]\n",
        "        if \"name\" in last_user_input.lower():\n",
        "            responses[\"neutral\"].append(\"By the way, what's your name?\")\n",
        "\n",
        "    # Use the NLP analysis to generate a more personalized and informative response:\n",
        "    if keywords:\n",
        "        response = f\"I noticed that you mentioned {keywords[0]}. Can you tell me more about that?\"\n",
        "    elif named_entities:\n",
        "        named_entity = named_entities[0][0]\n",
        "        response = f\"I know that {named_entity} is very important to you. How can I help you with that today?\"\n",
        "    else:\n",
        "        response = responses.get(sentiment, [\"I'm not sure how to respond to that.\"])\n",
        "\n",
        "    # Add some features of a\n",
        "    import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "class Chatbot:\n",
        "    def __init__(self):\n",
        "        self.sid = SentimentIntensityAnalyzer()\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def generate_response(self, user_input):\n",
        "        # Analyze the user input and determine the sentiment.\n",
        "        sentiment = self.sid.polarity_scores(user_input)['compound']\n",
        "\n",
        "        # Generate a response based on the sentiment.\n",
        "        if sentiment >= 0.05:\n",
        "            response = \"That's wonderful!\"\n",
        "        elif sentiment <= -0.05:\n",
        "            response = \"I'm sorry to hear that.\"\n",
        "        else:\n",
        "            response = \"I understand.\"\n",
        "\n",
        "        # Keep track of the conversation history.\n",
        "        self.conversation_history.append((user_input, response))\n",
        "\n",
        "        return response\n",
        "\n",
        "    def start_conversation(self):\n",
        "        print(\"Chatbot: Hello! How can I assist you today?\")\n",
        "\n",
        "        while True:\n",
        "            user_input = input(\"You: \")\n",
        "\n",
        "            if user_input.lower() == \"exit\":\n",
        "                break\n",
        "\n",
        "            response = self.generate_response(user_input)\n",
        "\n",
        "            print(f\"Chatbot: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot = Chatbot()\n",
        "    chatbot.start_conversation()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-8RQKtb0b2Z",
        "outputId": "27045500-8e50-409b-e175-a6905721d6a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CkOVTcz9l9Ys"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}